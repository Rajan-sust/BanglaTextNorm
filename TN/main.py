"""
__author__ = "Rajan Saha Raju"
"""

import argparse
from time import process_time
from tokenizer import tokenize_bangla_sentence
from llm import ask_llm
import json
from processes import (
    process_cardinal,
    process_ordinal,
    process_decimal,
    process_money,
    process_date,
    process_symbol,
    process_abbreviation,
    process_acronym
)

def main():
    parser = argparse.ArgumentParser(description="Normalize Bangla text.")
    parser.add_argument("--text", type=str, required=True, help="text to normalize")
    args = parser.parse_args()
    
    # first step: tokenization
    tokens_with_semiotics = tokenize_bangla_sentence(args.text)

    tokens_with_semiotics = json.loads(tokens_with_semiotics)
    
    normalized_tokens = []

    list_of_tokens = [obj['token'] for obj in tokens_with_semiotics]

    for obj in tokens_with_semiotics:
        if obj['semiotic'] == "PLAIN":
            normalized_tokens.append(obj['token'])
            
        elif obj["semiotic"] == "CARDINAL":
            normalized_tokens.append(process_cardinal(obj["token"]))

        elif obj["semiotic"] == "ORDINAL":
            normalized_tokens.append(process_ordinal(obj["token"]))

        elif obj["semiotic"] == "DECIMAL":
            normalized_tokens.append(process_decimal(obj["token"]))

        elif obj["semiotic"] == "MONEY":
            normalized_tokens.append(process_money(obj["token"]))

        elif obj["semiotic"] == "DATE":
            normalized_tokens.append(process_date(obj["token"]))    

        elif obj["semiotic"] == "SYMBOL":
            normalized_tokens.append(process_symbol(obj["token"], list_of_tokens))
        
        elif obj["semiotic"] == "ABBREVIATION":
            normalized_tokens.append(process_abbreviation(obj["token"], list_of_tokens))
        
        elif obj["semiotic"] == "ACRONYM":
            normalized_tokens.append(process_acronym(obj["token"], list_of_tokens))
        
    normalized_sentence = ' '.join(normalized_tokens)
    print('Initial normalized sentence:', normalized_sentence)

        # print("Normalized sentence:")
        # print(normalized_sentence)

        # call the LLM to quality check of the normalized sentence and fix the issues if any
    system_prompt = "You are a meticulous proofreader and corrector for Bangla text normalization."

    user_message = f"""
        You will be given an input-output pair generated by a deterministic system. 
        The deterministic system may contain errors and may fail to convert non-standard words to their standard forms. 
        Please correct the output.

        <example>
        Input: পরিমাণ ১২.৮৭ লক্ষ ঘ.মি.
        Output: পরিমাণ বারো লক্ষ আটাত্তর হাজার ঘন্টা মিটার
        Corrected Output: পরিমাণ বারো লক্ষ সাতাশি হাজার ঘন মিটার
        </example>

        <example>
        Input: ১০০ কেজি/হেক্টর। 
        Output: একশ কেজি/হেক্টর
        Corrected Output: একশ কেজি প্রতি হেক্টর।
        </example>

        <example>
        Input: ৫.৭৫টাকা
        Output: পাঁচ টাকা পঁচাত্তর পয়সা টাকা
        Corrected Output: পাঁচ টাকা পঁচাত্তর পয়সা
        </example>

        <instructions>
        - If the output is already correct, return it as-is without any changes.
        - Ensure proper spacing between words.
        - Correct any non-standard words to their standard forms.
        - Maintain the original meaning and formatting of the sentence.
        - Provide only the corrected output without additional text or explanations.
        </instructions>

        Input: {args.text}
        Output: {normalized_sentence}
        Corrected Output:
    """

    response = ask_llm(system_prompt, user_message)

    print('final response:', response)

if __name__ == "__main__":
    main()
